# AI Integration Rules

## Providers
Implement a provider interface:
- chat(messages, opts)
- embed(texts, opts)

Providers:
1) Online: OpenAI / Gemini (API key required)
2) Local: LM Studio OpenAI-compatible server (baseUrl configurable)

## Local AI compatibility
Assume OpenAI-compatible endpoints:
- baseUrl like http://localhost:1234/v1
- POST /v1/chat/completions
- POST /v1/embeddings

## Output contract
AI MUST return:
- ChangeSet JSON (adds/edits/links/merges/conflicts/trace)
- No direct filesystem writes

## Quality gates
- Every link/merge/conflict must include evidence noteIds
- Uncertain cases:
  - mark confidence low
  - still propose, but highlight in review UI
